{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# GA Data Science 5 (DAT5) - Lab6\n",
      "\n",
      "### Dimensionality Reduction and Principal Component Analysis (PCA)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# usual imports\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pylab as pl\n",
      "import pandas as pd\n",
      "\n",
      "# scikit-learn algorithms\n",
      "from sklearn.decomposition import PCA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Iris Dataset (i.e. scikit-learn iris)  \n",
      "Load the sklearn `iris` dataset.  This is one of the built-in datasets included in scikit-learn (and one we've seen before)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_iris\n",
      "iris = load_iris()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take a look at the dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(iris.DESCR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iris Plants Database\n",
        "\n",
        "Notes\n",
        "-----\n",
        "Data Set Characteristics:\n",
        "    :Number of Instances: 150 (50 in each of three classes)\n",
        "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
        "    :Attribute Information:\n",
        "        - sepal length in cm\n",
        "        - sepal width in cm\n",
        "        - petal length in cm\n",
        "        - petal width in cm\n",
        "        - class:\n",
        "                - Iris-Setosa\n",
        "                - Iris-Versicolour\n",
        "                - Iris-Virginica\n",
        "    :Summary Statistics:\n",
        "    ============== ==== ==== ======= ===== ====================\n",
        "                    Min  Max   Mean    SD   Class Correlation\n",
        "    ============== ==== ==== ======= ===== ====================\n",
        "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
        "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
        "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
        "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
        "    ============== ==== ==== ======= ===== ====================\n",
        "    :Missing Attribute Values: None\n",
        "    :Class Distribution: 33.3% for each of 3 classes.\n",
        "    :Creator: R.A. Fisher\n",
        "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
        "    :Date: July, 1988\n",
        "\n",
        "This is a copy of UCI ML iris datasets.\n",
        "http://archive.ics.uci.edu/ml/datasets/Iris\n",
        "\n",
        "The famous Iris database, first used by Sir R.A Fisher\n",
        "\n",
        "This is perhaps the best known database to be found in the\n",
        "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
        "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
        "data set contains 3 classes of 50 instances each, where each class refers to a\n",
        "type of iris plant.  One class is linearly separable from the other 2; the\n",
        "latter are NOT linearly separable from each other.\n",
        "\n",
        "References\n",
        "----------\n",
        "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
        "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
        "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
        "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
        "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
        "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
        "     Structure and Classification Rule for Recognition in Partially Exposed\n",
        "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
        "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
        "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
        "     on Information Theory, May 1972, 431-433.\n",
        "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
        "     conceptual clustering system finds 3 classes in the data.\n",
        "   - Many, many more ...\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print iris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'target_names': array(['setosa', 'versicolor', 'virginica'], \n",
        "      dtype='|S10'), 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
        "       [ 4.9,  3. ,  1.4,  0.2],\n",
        "       [ 4.7,  3.2,  1.3,  0.2],\n",
        "       [ 4.6,  3.1,  1.5,  0.2],\n",
        "       [ 5. ,  3.6,  1.4,  0.2],\n",
        "       [ 5.4,  3.9,  1.7,  0.4],\n",
        "       [ 4.6,  3.4,  1.4,  0.3],\n",
        "       [ 5. ,  3.4,  1.5,  0.2],\n",
        "       [ 4.4,  2.9,  1.4,  0.2],\n",
        "       [ 4.9,  3.1,  1.5,  0.1],\n",
        "       [ 5.4,  3.7,  1.5,  0.2],\n",
        "       [ 4.8,  3.4,  1.6,  0.2],\n",
        "       [ 4.8,  3. ,  1.4,  0.1],\n",
        "       [ 4.3,  3. ,  1.1,  0.1],\n",
        "       [ 5.8,  4. ,  1.2,  0.2],\n",
        "       [ 5.7,  4.4,  1.5,  0.4],\n",
        "       [ 5.4,  3.9,  1.3,  0.4],\n",
        "       [ 5.1,  3.5,  1.4,  0.3],\n",
        "       [ 5.7,  3.8,  1.7,  0.3],\n",
        "       [ 5.1,  3.8,  1.5,  0.3],\n",
        "       [ 5.4,  3.4,  1.7,  0.2],\n",
        "       [ 5.1,  3.7,  1.5,  0.4],\n",
        "       [ 4.6,  3.6,  1. ,  0.2],\n",
        "       [ 5.1,  3.3,  1.7,  0.5],\n",
        "       [ 4.8,  3.4,  1.9,  0.2],\n",
        "       [ 5. ,  3. ,  1.6,  0.2],\n",
        "       [ 5. ,  3.4,  1.6,  0.4],\n",
        "       [ 5.2,  3.5,  1.5,  0.2],\n",
        "       [ 5.2,  3.4,  1.4,  0.2],\n",
        "       [ 4.7,  3.2,  1.6,  0.2],\n",
        "       [ 4.8,  3.1,  1.6,  0.2],\n",
        "       [ 5.4,  3.4,  1.5,  0.4],\n",
        "       [ 5.2,  4.1,  1.5,  0.1],\n",
        "       [ 5.5,  4.2,  1.4,  0.2],\n",
        "       [ 4.9,  3.1,  1.5,  0.1],\n",
        "       [ 5. ,  3.2,  1.2,  0.2],\n",
        "       [ 5.5,  3.5,  1.3,  0.2],\n",
        "       [ 4.9,  3.1,  1.5,  0.1],\n",
        "       [ 4.4,  3. ,  1.3,  0.2],\n",
        "       [ 5.1,  3.4,  1.5,  0.2],\n",
        "       [ 5. ,  3.5,  1.3,  0.3],\n",
        "       [ 4.5,  2.3,  1.3,  0.3],\n",
        "       [ 4.4,  3.2,  1.3,  0.2],\n",
        "       [ 5. ,  3.5,  1.6,  0.6],\n",
        "       [ 5.1,  3.8,  1.9,  0.4],\n",
        "       [ 4.8,  3. ,  1.4,  0.3],\n",
        "       [ 5.1,  3.8,  1.6,  0.2],\n",
        "       [ 4.6,  3.2,  1.4,  0.2],\n",
        "       [ 5.3,  3.7,  1.5,  0.2],\n",
        "       [ 5. ,  3.3,  1.4,  0.2],\n",
        "       [ 7. ,  3.2,  4.7,  1.4],\n",
        "       [ 6.4,  3.2,  4.5,  1.5],\n",
        "       [ 6.9,  3.1,  4.9,  1.5],\n",
        "       [ 5.5,  2.3,  4. ,  1.3],\n",
        "       [ 6.5,  2.8,  4.6,  1.5],\n",
        "       [ 5.7,  2.8,  4.5,  1.3],\n",
        "       [ 6.3,  3.3,  4.7,  1.6],\n",
        "       [ 4.9,  2.4,  3.3,  1. ],\n",
        "       [ 6.6,  2.9,  4.6,  1.3],\n",
        "       [ 5.2,  2.7,  3.9,  1.4],\n",
        "       [ 5. ,  2. ,  3.5,  1. ],\n",
        "       [ 5.9,  3. ,  4.2,  1.5],\n",
        "       [ 6. ,  2.2,  4. ,  1. ],\n",
        "       [ 6.1,  2.9,  4.7,  1.4],\n",
        "       [ 5.6,  2.9,  3.6,  1.3],\n",
        "       [ 6.7,  3.1,  4.4,  1.4],\n",
        "       [ 5.6,  3. ,  4.5,  1.5],\n",
        "       [ 5.8,  2.7,  4.1,  1. ],\n",
        "       [ 6.2,  2.2,  4.5,  1.5],\n",
        "       [ 5.6,  2.5,  3.9,  1.1],\n",
        "       [ 5.9,  3.2,  4.8,  1.8],\n",
        "       [ 6.1,  2.8,  4. ,  1.3],\n",
        "       [ 6.3,  2.5,  4.9,  1.5],\n",
        "       [ 6.1,  2.8,  4.7,  1.2],\n",
        "       [ 6.4,  2.9,  4.3,  1.3],\n",
        "       [ 6.6,  3. ,  4.4,  1.4],\n",
        "       [ 6.8,  2.8,  4.8,  1.4],\n",
        "       [ 6.7,  3. ,  5. ,  1.7],\n",
        "       [ 6. ,  2.9,  4.5,  1.5],\n",
        "       [ 5.7,  2.6,  3.5,  1. ],\n",
        "       [ 5.5,  2.4,  3.8,  1.1],\n",
        "       [ 5.5,  2.4,  3.7,  1. ],\n",
        "       [ 5.8,  2.7,  3.9,  1.2],\n",
        "       [ 6. ,  2.7,  5.1,  1.6],\n",
        "       [ 5.4,  3. ,  4.5,  1.5],\n",
        "       [ 6. ,  3.4,  4.5,  1.6],\n",
        "       [ 6.7,  3.1,  4.7,  1.5],\n",
        "       [ 6.3,  2.3,  4.4,  1.3],\n",
        "       [ 5.6,  3. ,  4.1,  1.3],\n",
        "       [ 5.5,  2.5,  4. ,  1.3],\n",
        "       [ 5.5,  2.6,  4.4,  1.2],\n",
        "       [ 6.1,  3. ,  4.6,  1.4],\n",
        "       [ 5.8,  2.6,  4. ,  1.2],\n",
        "       [ 5. ,  2.3,  3.3,  1. ],\n",
        "       [ 5.6,  2.7,  4.2,  1.3],\n",
        "       [ 5.7,  3. ,  4.2,  1.2],\n",
        "       [ 5.7,  2.9,  4.2,  1.3],\n",
        "       [ 6.2,  2.9,  4.3,  1.3],\n",
        "       [ 5.1,  2.5,  3. ,  1.1],\n",
        "       [ 5.7,  2.8,  4.1,  1.3],\n",
        "       [ 6.3,  3.3,  6. ,  2.5],\n",
        "       [ 5.8,  2.7,  5.1,  1.9],\n",
        "       [ 7.1,  3. ,  5.9,  2.1],\n",
        "       [ 6.3,  2.9,  5.6,  1.8],\n",
        "       [ 6.5,  3. ,  5.8,  2.2],\n",
        "       [ 7.6,  3. ,  6.6,  2.1],\n",
        "       [ 4.9,  2.5,  4.5,  1.7],\n",
        "       [ 7.3,  2.9,  6.3,  1.8],\n",
        "       [ 6.7,  2.5,  5.8,  1.8],\n",
        "       [ 7.2,  3.6,  6.1,  2.5],\n",
        "       [ 6.5,  3.2,  5.1,  2. ],\n",
        "       [ 6.4,  2.7,  5.3,  1.9],\n",
        "       [ 6.8,  3. ,  5.5,  2.1],\n",
        "       [ 5.7,  2.5,  5. ,  2. ],\n",
        "       [ 5.8,  2.8,  5.1,  2.4],\n",
        "       [ 6.4,  3.2,  5.3,  2.3],\n",
        "       [ 6.5,  3. ,  5.5,  1.8],\n",
        "       [ 7.7,  3.8,  6.7,  2.2],\n",
        "       [ 7.7,  2.6,  6.9,  2.3],\n",
        "       [ 6. ,  2.2,  5. ,  1.5],\n",
        "       [ 6.9,  3.2,  5.7,  2.3],\n",
        "       [ 5.6,  2.8,  4.9,  2. ],\n",
        "       [ 7.7,  2.8,  6.7,  2. ],\n",
        "       [ 6.3,  2.7,  4.9,  1.8],\n",
        "       [ 6.7,  3.3,  5.7,  2.1],\n",
        "       [ 7.2,  3.2,  6. ,  1.8],\n",
        "       [ 6.2,  2.8,  4.8,  1.8],\n",
        "       [ 6.1,  3. ,  4.9,  1.8],\n",
        "       [ 6.4,  2.8,  5.6,  2.1],\n",
        "       [ 7.2,  3. ,  5.8,  1.6],\n",
        "       [ 7.4,  2.8,  6.1,  1.9],\n",
        "       [ 7.9,  3.8,  6.4,  2. ],\n",
        "       [ 6.4,  2.8,  5.6,  2.2],\n",
        "       [ 6.3,  2.8,  5.1,  1.5],\n",
        "       [ 6.1,  2.6,  5.6,  1.4],\n",
        "       [ 7.7,  3. ,  6.1,  2.3],\n",
        "       [ 6.3,  3.4,  5.6,  2.4],\n",
        "       [ 6.4,  3.1,  5.5,  1.8],\n",
        "       [ 6. ,  3. ,  4.8,  1.8],\n",
        "       [ 6.9,  3.1,  5.4,  2.1],\n",
        "       [ 6.7,  3.1,  5.6,  2.4],\n",
        "       [ 6.9,  3.1,  5.1,  2.3],\n",
        "       [ 5.8,  2.7,  5.1,  1.9],\n",
        "       [ 6.8,  3.2,  5.9,  2.3],\n",
        "       [ 6.7,  3.3,  5.7,  2.5],\n",
        "       [ 6.7,  3. ,  5.2,  2.3],\n",
        "       [ 6.3,  2.5,  5. ,  1.9],\n",
        "       [ 6.5,  3. ,  5.2,  2. ],\n",
        "       [ 6.2,  3.4,  5.4,  2.3],\n",
        "       [ 5.9,  3. ,  5.1,  1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
        "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'DESCR': 'Iris Plants Database\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']}\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = iris.data\n",
      "y = iris.target\n",
      "target_names = iris.target_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The PCA algorithm takes an argument `n_components` which specifyies how many of the principal components we want to keep.  This dataset has only 4 features, so let's try keeping 2 to start: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create the model and fit the data\n",
      "pca = PCA(n_components=2)\n",
      "X_r = pca.fit(X).transform(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How much of the variance do the first two principal components explain?  The PCA class has an attribute `explained_variance_ratio_` that reports this information:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Percentage of variance explained (first two components):\n",
      "print \"First component: \" + str(pca.explained_variance_ratio_[0])\n",
      "print \"Second component: \" + str(pca.explained_variance_ratio_[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "First component: 0.924616207174\n",
        "Second component: 0.0530155678505\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that the first principal component explains most of the variance.  Since we kept only 2 components we can use a simple 2-dimensional plot to view the datapoints in the new coordinate system.  We'll label them using our known target info:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pl.figure()\n",
      "# for c, i, target_name in zip(\"rgb\", [0, 1, 2], target_names):\n",
      "#     pl.scatter(X_r[y == i, 0], X_r[y == i, 1], c=c, label=target_name)\n",
      "# pl.legend()\n",
      "# pl.title('PCA of IRIS dataset')\n",
      "\n",
      "# pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use a scree plot to help validate our choice of `n`.  Let's refit the model, but this time keep all components - this is the default behavior if `n_components` is not specified:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create the model and fit the data - no n_components set:\n",
      "# ...\n",
      "# ... "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As before, the explained variance ratios are in `pca.explained_variance_ratio_`, but this time there should be 4 ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ... \n",
      "# print ratios"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print pca.components_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print X_r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# comp_id = [1, 2, 3, 4]             # id number of component\n",
      "# fig = plt.figure(figsize=(8,5))\n",
      "# ...\n",
      "# plt.title('Scree Plot')\n",
      "# plt.xlabel('Principal Component')\n",
      "# plt.ylabel('Eigenvalue')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is a clear 'elbow in the curve', so it looks like our choice of `2` components was ok.  Let's look at another dataset that has more features per record.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Handwritten Digits Dataset (i.e. scikit-learn digits)  \n",
      "\n",
      "Load the sklearn `digits` dataset, which contains a set of 8x8 pixel images of handwritten digits.  This is one of the built-in datasets included in scikit-learn."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ... \n",
      "# ... "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take a look at the dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print(digits.DESCR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that each row in the dataset has 64 features, one for each of the individual pixels making up the image, where the value of each feature is the greyscale level (0 to 15)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print digits"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ... \n",
      "\n",
      "# print(\"data shape: %r, target shape: %r\" % (X.shape, y.shape))\n",
      "# print(\"classes: %r\" % list(np.unique(y)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ...\n",
      "# print(\"n_samples=%d\" % n_samples)\n",
      "# print(\"n_features=%d\" % n_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's a small routine to visually plot the first 400 rows (i.e. digits) in the dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# helper function for plot images of the digits\n",
      "# ref: anfibil\n",
      "\n",
      "# note: this uses pandas indexing, so temporarily load into pandas dataframe\n",
      "\n",
      "# Xpd = pd.DataFrame(digits.data) # explanatory (or independent or feature) variables\n",
      "\n",
      "# n_img_per_row = 20                                    # number of digits per row\n",
      "# img = np.zeros((10*n_img_per_row, 10*n_img_per_row))  # generate a new 200x200 array filled with zeros\n",
      "# for i in range(n_img_per_row):\n",
      "#     ix = 10 * i + 1\n",
      "#     for j in range(n_img_per_row):\n",
      "#         iy = 10 * j + 1\n",
      "#         img[ix:ix+8, iy:iy+8] = Xpd.ix[i*n_img_per_row + j].reshape((8, 8)) # set each 8x8 area of the img to the values of each row (reshaped from 1x64 to 8x8)\n",
      "\n",
      "# pl.figure(figsize=(8, 8), dpi=250)     # define a figure, with size (width and height) and resolution\n",
      "# axes(frameon = 0)                      # turn off the axes border\n",
      "# pl.imshow(img, cmap=pl.cm.binary)      # show the image using a binary color map\n",
      "# pl.xticks([]) # no x ticks\n",
      "# pl.yticks([]) # no y ticks\n",
      "# pl.title('A Selection from the 64-Dimensional Digits Dataset\\n', fontsize=16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# helper function for plotting images\n",
      "# ref: ogrisel\n",
      "\n",
      "def plot_gallery(data, labels, shape, interpolation='nearest'):\n",
      "    for i in range(data.shape[0]):\n",
      "        plt.subplot(1, data.shape[0], (i + 1))\n",
      "        plt.imshow(data[i].reshape(shape), interpolation=interpolation, cmap=pl.cm.binary)\n",
      "        plt.title(labels[i])\n",
      "        plt.xticks(()), plt.yticks(())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# subsample = np.random.permutation(X.shape[0])[:4]      # pick 4 random records \n",
      "# images = X[subsample]\n",
      "# labels = ['True class: %d' % l for l in y[subsample]]  # label with the true (known) value\n",
      "# plot_gallery(images, labels, shape=(8, 8))             # plot them in grayscale"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# run normal PCA\n",
      "# X, y = digits.data, digits.target\n",
      "\n",
      "# ...\n",
      "# ...\n",
      "\n",
      "# ... \n",
      "# print ratios"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from itertools import cycle\n",
      "\n",
      "# colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
      "# markers = ['+', 'o', '^', 'v', '<', '>', 'D', 'h', 's']\n",
      "# for i, c, m in zip(np.unique(y), cycle(colors), cycle(markers)):\n",
      "#     plt.scatter(X_r[y == i, 0], X_r[y == i, 1],\n",
      "#         c=c, marker=m, label=i, alpha=0.5)\n",
      "    \n",
      "# _ = plt.legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What do these components look like?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# labels = ['Component #%d' % i for i in range(len(pca.components_))]\n",
      "# plot_gallery(pca.components_, labels, shape=(8, 8))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Was 2 a good choice - i.e. can we capture enough of the variance with just 2 components?  Let's see what the rest would have looked like:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create the model and fit the data - no n_components set:\n",
      "# X, y = digits.data, digits.target\n",
      "\n",
      "# pca = PCA()  # notice we did not pass n_components!\n",
      "# X_r = pca.fit(X).transform(X)\n",
      "\n",
      "# ratios = pca.explained_variance_ratio_\n",
      "# print ratios"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As before, a scree plot can help us pick a good n."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# comp_id = [i + 1 for i in range(64)]             # ids of components\n",
      "# fig = plt.figure(figsize=(8,5))\n",
      "# plt.plot(comp_id, ratios, 'ro-', linewidth=2)\n",
      "# plt.title('Scree Plot')\n",
      "# plt.xlabel('Principal Component')\n",
      "# plt.ylabel('Eigenvalue')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Based on this plot we would probably want to set `n_components` to somewhere around 10 - 12 for a good tradeoff between model complexity and coverage of the variance.        "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print X_r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "### A Few More Examples: \n",
      "\n",
      "1. 'Favorite Style '\n",
      "\n",
      "2. 'Cool kids in high school'\n",
      "\n",
      "3. [Congressional Ideology](https://www.govtrack.us/about/analysis#ideology](https://www.govtrack.us/about/analysis#ideology)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "refs:\n",
      "\n",
      "Other PCA notebooks: [ogrisel](http://nbviewer.ipython.org/github/ogrisel/parallel_ml_tutorial/blob/master/notebooks/02%20-%20Model%20Selection%20and%20Assessment.ipynb) , [anfibil](http://nbviewer.ipython.org/github/anfibil/cse40647.sp14/blob/master/8%20-%20Dimensionality%20Reduction.ipynb)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    }
   ],
   "metadata": {}
  }
 ]
}